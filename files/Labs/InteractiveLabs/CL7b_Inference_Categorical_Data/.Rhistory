View(DF)
View(DF)
library(tidyverse)
library(MASS) # for mvrnorm
library(mvnfast) # for dmvn
library(Matrix)
library(caret)
library(glmnet)
library(hierNet)
library(ncvreg)
library(RAMP)
library(iRF)
library(randomForest) # basic implementation
library(ranger)       # a faster implementation of randomForest
library(Boruta)       # Selection of important features for RF
library(parallel)
library(mccr)
library(MFSIS)
(core.num <- detectCores())
DF.Gen <- function(n, p, mod){
# Models from Duroux and Scornet (2018)
{
if(mod < 13){
dependt.Cov = matrix(c(1, 0.3, 0.3, 0.6, 0.6,
0.3, 1, 0.3, 0.2, 0.1,
0.3, 0.3, 1, 0.2, 0.1,
0.6, 0.2, 0.2, 1, 0.1,
0.6, 0.1, 0.1, 0.1, 1), nrow = 5, byrow = TRUE)
Zero.Mat = matrix(0, nrow = 5, ncol = p-5)
Sig = rbind(cbind(dependt.Cov, Zero.Mat), cbind(t(Zero.Mat), diag(p-5)))
# Main effects only
X.m1 = SimDesign::rmvnorm(n, mean = rep(0, p), sigma = Sig)
colnames(X.m1) = paste0("X", 1:p)
# Interaction effects
id1 = unlist(sapply(1:p, function(x) x:p))
id2 = rep(1:p, p:1)
X.i = sapply(1:length(id1), function(x) X.m1[, id2[x]]*X.m1[, id1[x]])
colnames(X.i) = sapply(1:length(id1), function(x) paste0("X", id2[x], "X", id1[x]))
X = cbind(X.m1, X.i)
}
else{
X.m2 = matrix(runif(n*p), nrow = n, ncol = p)
colnames(X.m2) = paste0("X", 1:p)
# Standardization (Mean Clustering)
X.m2 = apply(X.m2, 2, scale, scale = FALSE) # The quadratic term of a centered variable can avoid collinearity
# Interaction effects
id1 = unlist(sapply(1:p, function(x) x:p))
id2 = rep(1:p, p:1)
X.i = sapply(1:length(id1), function(x) X.m2[, id2[x]]*X.m2[, id1[x]])
colnames(X.i) = sapply(1:length(id1), function(x) paste0("X", id2[x], "X", id1[x]))
X = cbind(X.m2, X.i)
Xt = 2*(X - 0.5)
}
}
# Models from Jain and Xu (2021)
if (mod==5){
prob1 = 1/(1 + exp(-(-0.5 + (1 + 0.2*X[,1] + 0.3*X[,2] + 0.4*X[,3] + 0.3*X[,1]*X[,2]))))
Y = rbinom(n, 1, prob1) # Balanced Response case with main effect
}
if (mod==6){
prob1 = 1/(1 + exp(-(-2 + (1 + 0.2*X[,1] + 0.3*X[,2] + 0.4*X[,3] + 0.3*X[,1]*X[,2]))))
Y = rbinom(n, 1, prob1) # Imbalanced Response case with main effect
}
if (mod==7){
prob2 = 1/(1 + exp(-(-0.5 + (1 + 0.4*X[,3] + 0.3*X[,1]*X[,2]))))
Y = rbinom(n, 1, prob2) # Balanced Response case with no main effect (parent variable)
}
if (mod==8){
prob2 = 1/(1 + exp(-(-2 + (1 + 0.4*X[,3] + 0.3*X[,1]*X[,2]))))
Y = rbinom(n, 1, prob2) # Imbalanced Response case with no main effect (parent variable)
}
if (mod==9){
prob6 = 1/(1 + exp(-(-0.5 + (1 + 0.4*X[,3] + 0.3*(X[,1]>0.5 & X[,2]>0.5)))))
Y = rbinom(n, 1, prob6) # Balanced Response case )
}
if (mod==10){
prob6 = 1/(1 + exp(-(-2 + (1 + 0.4*X[,3] + 0.3*(X[,1]>0.5 & X[,2]>0.5)))))
Y = rbinom(n, 1, prob6) # Imbalanced Response case
}
if (mod==11){
prob6 = 1/(1 + exp(-(-0.5 + (1 + 0.2*X[,1] + 0.3*X[,2] + 0.3*X[,1]*X[,2] + 0.3*(X[,3]>0.5 & X[,4]>0.5)))))
Y = rbinom(n, 1, prob6) # Balanced Response case
}
if (mod==12){
prob6 = 1/(1 + exp(-(-2 + (1 + 0.2*X[,1] + 0.3*X[,2] + 0.3*X[,1]*X[,2] + 0.3*(X[,3]>0.5 & X[,4]>0.5)))))
Y = rbinom(n, 1, prob6) # Imbalanced Response case with
}
Dat = data.frame(cbind(Y, X))
# colnames(Dat) = c("Y", paste0("x", 1:p))
return(Dat)
}
n = 500
p = 100
mod = 5
DF <- DF.Gen(n , p, mod)
DF.X <- as.matrix(DF[,-1])
DF.Y <- as.vector(DF[, 1])
DcSIS_main <- function(n, p, mod){
#Generate probability that A = 1 given covariates
# P <-  exp(X)/ (1+exp(X))
DF.X <- as.matrix(DF[,-1])
#Generate treatment indicators
# Aorig <- rbinom(n, 1, P)
#Generate outcomes
# Yorig <- Aorig + Xorig %*% coef2 + rnorm(n, mean=0, sd=1)
# colnames(Yorig) <- "Y"
# Yorig <- as.vector(Yorig)
DF.Y <- as.vector(DF[, 1])
#
#################################################################################################
# Fit the SIS model without regularization, iter = FALSE
DC_SIS_model <- MFSIS(X = DF.X, Y = DF.Y, nsis = n/log(n)*log((p*(p+1))/2),
method = "DCSIS")
return(DC_SIS_model)
}
set.seed(151)
result_Dc_main <- list(replicate(100, DcSIS_main(n = 500, p = 100, mod = 5)))
View(result_Dc_main)
set.seed(151)
result_Dc_main <- list(replicate(5, DcSIS_main(n = 500, p = 100, mod = 5)))
View(result_Dc_main)
result_Dc_main[[1]]
g <- as.data.frame(result_Dc_main)
### Extract selected terms
g$index <- 1:nrow(g)
g_trans <- melt(g, id.vars='index',var='pred')
DC_Sel <- g_trans %>% group_by(value) %>%
summarise(Count = n()) %>% arrange(-Count) %>%
head(686) %>% select(value)
DC_Sel
install.packages("reshape")
library(reshape)
g <- as.data.frame(result_Dc_main)
### Extract selected terms
g$index <- 1:nrow(g)
g_trans <- melt(g, id.vars='index',var='pred')
DC_Sel <- g_trans %>% group_by(value) %>%
summarise(Count = n()) %>% arrange(-Count) %>%
head(686) %>% select(value)
DC_Sel
g <- as.data.frame(result_Dc_main)
### Extract selected terms
g$index <- 1:nrow(g)
g_trans <- melt(g, id.vars='index',var='pred')
DC_Sel <- g_trans %>%
group_by(value) %>%
summarise(Count = n()) %>%
arrange(-Count) %>%
head(686) %>%
dplyr::select(value)
DC_Sel
print(DC_Sel, n = 686)
n/log(n)*log((p*(p+1))/2
)
nsis = p+log((p*(p+1))/2)
nsis = p/log(p)+log((p*(p+1))/2)
log(p)
log(n)
500*500 + 3*500
251500/2
library(tidyverse)
library(openintro)
library(MASS)
library(readr)
library(learnr)
library(ggplot2)
library(gradethis) #remotes::install_github("rstudio/gradethis")
library(learnrhash) #devtools::install_github("rundel/learnrhash")
library(gapminder)
library(emo) #devtools::install_github("hadley/emo")
library(png)
library(grid)
tutorial_options(exercise.timelimit = 120,
exercise.checker = gradethis::grade_learnr)
gradethis_setup(exercise.reveal_solution = FALSE)
global_monitor <- tibble(
scientist_work = c(rep("Benefits", 80000), rep("Doesn't benefit", 20000)))
sample_props50 <- global_monitor %>%
rep_sample_n(size = 50, reps = 15000, replace = TRUE) %>%
count(scientist_work) %>%
mutate(p_hat = n /sum(n)) %>%
filter(scientist_work == "Doesn't benefit")
library(tidyverse)
library(openintro)
library(MASS)
library(readr)
library(learnr)
library(ggplot2)
library(gradethis) #remotes::install_github("rstudio/gradethis")
library(learnrhash) #devtools::install_github("rundel/learnrhash")
library(gapminder)
library(emo) #devtools::install_github("hadley/emo")
library(png)
library(grid)
tutorial_options(exercise.timelimit = 120,
exercise.checker = gradethis::grade_learnr)
gradethis_setup(exercise.reveal_solution = FALSE)
library(tidyverse)
library(openintro)
library(infer)
global_monitor <- tibble(
scientist_work = c(rep("Benefits", 80000), rep("Doesn't benefit", 20000)))
sample_props50 <- global_monitor %>%
rep_sample_n(size = 50, reps = 15000, replace = TRUE) %>%
count(scientist_work) %>%
mutate(p_hat = n /sum(n)) %>%
filter(scientist_work == "Doesn't benefit")
ggplot(data = sample_props50, aes(x = p_hat)) +
geom_histogram(binwidth = 0.02) +
labs(
x = "p_hat (Doesn't benefit)",
title = "Sampling distribution of p_hat",
subtitle = "Sample size = 50, Number of samples = 15000"
)
library(tidyverse)
library(openintro)
library(infer)
library(tidyverse)
library(openintro)
library(infer)
global_monitor <- tibble(
scientist_work = c(rep("Benefits", 80000), rep("Doesn't benefit", 20000)))
sample_props50 <- global_monitor %>%
rep_sample_n(size = 50, reps = 15000, replace = TRUE) %>%
count(scientist_work) %>%
mutate(p_hat = n /sum(n)) %>%
filter(scientist_work == "Doesn't benefit")
ggplot(data = sample_props50, aes(x = p_hat)) +
geom_histogram(binwidth = 0.02) +
labs(
x = "p_hat (Doesn't benefit)",
title = "Sampling distribution of p_hat",
subtitle = "Sample size = 50, Number of samples = 15000"
)
library(infer)
global_monitor <- tibble(scientist_work = c(rep("Benefits", 80000), rep("Doesn't benefit", 20000)))
sample_props50 <- global_monitor %>%
rep_sample_n(size = 50, reps = 15000, replace = TRUE) %>%
count(scientist_work) %>%
mutate(p_hat = n /sum(n)) %>%
filter(scientist_work == "Doesn't benefit")
ggplot(data = sample_props50, aes(x = p_hat)) +
geom_histogram(binwidth = 0.02) +
labs(
x = "p_hat (Doesn't benefit)",
title = "Sampling distribution of p_hat",
subtitle = "Sample size = 50, Number of samples = 15000"
)
library(infer)
global_monitor <- tibble(scientist_work = c(rep("Benefits", 80000), rep("Doesn't benefit", 20000)))
sample_props50 <- global_monitor %>%
rep_sample_n(size = 50, reps = 15000, replace = TRUE) %>%
count(scientist_work) %>%
mutate(p_hat = n /sum(n)) %>%
filter(scientist_work == "Benefits")
ggplot(data = sample_props50, aes(x = p_hat)) +
geom_histogram(binwidth = 0.02) +
labs(
x = "p_hat (Doesn't benefit)",
title = "Sampling distribution of p_hat",
subtitle = "Sample size = 50, Number of samples = 15000"
)
install.packages(c("broom", "cachem", "chron", "data.table", "dbplyr", "DescTools", "dtplyr", "fastmap", "fBasics", "fma", "forecast", "Formula", "fpp2", "future", "gapminder", "gdtools", "ggsci", "gh", "gss", "h2o", "haven", "Hmisc", "httr", "igraph", "inum", "ipred", "lava", "lavaan", "lme4", "magick", "MASS", "MatchIt", "mgcv", "multcomp", "mvnfast", "openssl", "packrat", "party", "partykit", "precrec", "RcppArmadillo", "RcppParallel", "recipes", "renv", "Rfast", "rlang", "RSQLite", "seriation", "spatstat.utils", "survival", "testthat", "tibble", "tidyverse", "triebeard", "TSP", "xts"))
install.packages(c("fastmap", "rlang", "tibble"))
remove.packages(c("fastmap", "rlang", "tibble"))
install.packages("fastmap")
install.packages("rlang")
install.packages("tibble")
library(tidyverse)
library(MASS) # for mvrnorm
library(mvnfast) # for dmvn
library(Matrix)
library(caret)
library(glmnet)
library(hierNet)
library(ncvreg)
library(RAMP)
library(iRF)
library(randomForest) # basic implementation
library(ranger)       # a faster implementation of randomForest
library(Boruta)       # Selection of important features for RF
library(parallel)
library(MFSIS)
library(reshape)
(core.num <- detectCores())
DF.Gen <- function(n, p, mod){
# Models from Duroux and Scornet (2018)
{
if(mod < 3){
dependt.Cov = matrix(c(1, 0.3, 0.3, 0.6, 0.6,
0.3, 1, 0.3, 0.2, 0.1,
0.3, 0.3, 1, 0.2, 0.1,
0.6, 0.2, 0.2, 1, 0.1,
0.6, 0.1, 0.1, 0.1, 1), nrow = 5, byrow = TRUE)
Zero.Mat = matrix(0, nrow = 5, ncol = p-5)
Sig = rbind(cbind(dependt.Cov, Zero.Mat), cbind(t(Zero.Mat), diag(p-5)))
# Main effects only
X.m1 = SimDesign::rmvnorm(n, mean = rep(0, p), sigma = Sig)
colnames(X.m1) = paste0("X", 1:p)
# Interaction effects
id1 = unlist(sapply(1:p, function(x) x:p))
id2 = rep(1:p, p:1)
X.i = sapply(1:length(id1), function(x) X.m1[, id2[x]]*X.m1[, id1[x]])
colnames(X.i) = sapply(1:length(id1), function(x) paste0("X", id2[x], "X", id1[x]))
X = cbind(X.m1, X.i)
}
else{
X.m2 = matrix(runif(n*p), nrow = n, ncol = p)
colnames(X.m2) = paste0("X", 1:p)
# Standardization (Mean Clustering)
X.m2 = apply(X.m2, 2, scale, scale = FALSE) # The quadratic term of a centered variable can avoid collinearity
# Interaction effects
id1 = unlist(sapply(1:p, function(x) x:p))
id2 = rep(1:p, p:1)
X.i = sapply(1:length(id1), function(x) X.m2[, id2[x]]*X.m2[, id1[x]])
colnames(X.i) = sapply(1:length(id1), function(x) paste0("X", id2[x], "X", id1[x]))
X = cbind(X.m2, X.i)
Xt = 2*(X - 0.5)
}
}
# Models from Jain and Xu (2021)
if (mod==1){
Y = 1 + 0.2*X[,1] + 0.3*X[,2] + 0.4*X[,3] + 0.3*X[,1]*X[,2] + rnorm(n, mean = 0, sd = sqrt(.25))
}
if (mod==2){
Y = 1 + 0.4*X[,3] + 0.3*X[,1]*X[,2] + rnorm(n,mean = 0, sd = sqrt(0.25))
}
if (mod==3){
Y = 1 + 0.4*X[,3] + 0.3*(X[,1]>0.5 & X[,2]>0.5) + rnorm(n, mean = 0, sd = sqrt(.25))
}
if (mod==4){
Y = 1 + 0.2*X[,1] + 0.3*X[,2] + 0.3*X[,1]*X[,2] + 0.3*(X[,3]>0.5 & X[,4]>0.5) + rnorm(n, mean = 0, sd = sqrt(.25))
}
Dat = data.frame(cbind(Y, X))
# colnames(Dat) = c("Y", paste0("x", 1:p))
return(Dat)
}
n = 500
p = 500
n.val <- 500
p.val <- 500
mod <- 1
iter <- 10
DF <- DF.Gen(n,p,mod)
DCSIS.func <- function(n, p, mod){
DF.X <- as.matrix(DF[,-1])
DF.Y <- as.vector(DF[,1])
DCSIS.mod <- MFSIS(X = DF.X, Y = DF.Y, nsis = n/log(n)*log((p*(p+1))/2), method = "DCSIS")
return(DCSIS.mod)
}
set.seed(1788)
DCSIS_iter <- list(replicate(iter, DCSIS.func(n = n.val, p = p.val, mod = mod)))
DCSIS_iter
dat <- as.data.frame(DCSIS_iter)
dat$ind <- 1:nrow(dat) #creating index set for the selection
dat_tidy <- melt(dat, id.vars = "ind", var = "pred")
Selected_DCSIS <- dat_tidy %>%
group_by(value) %>%
summarise(Count = n()) %>%
arrange(-Count) %>%
head(686) %>%  # Number of nsis: 'n/log(n)*log((p*(p+1))/2)'
mutate(value = value + 1) %>%
dplyr::pull(value)
print(Selected_DCSIS, n = 686)
dat <- as.data.frame(DCSIS_iter)
dat$ind <- 1:nrow(dat) #creating index set for the selection
dat_tidy <- melt(dat, id.vars = "ind", var = "pred")
Selected_DCSIS <- dat_tidy %>%
group_by(value) %>%
summarise(Count = n()) %>%
arrange(-Count) %>%
head(944) %>%  # Number of nsis: 'n/log(n)*log((p*(p+1))/2)'
mutate(value = value + 1) %>%
dplyr::pull(value)
print(Selected_DCSIS, n = 944)
n/log(n)*log((p*(p+1))/2)
P <- DF %>%
dplyr::select(Y, Selected_DCSIS)
names(P)
View(P)
print(Selected_DCSIS, n = 945)
library(tidyverse)
library(MASS) # for mvrnorm
library(mvnfast) # for dmvn
library(Matrix)
library(caret)
library(glmnet)
library(hierNet)
library(ncvreg)
library(RAMP)
library(iRF)
library(randomForest) # basic implementation
library(ranger)       # a faster implementation of randomForest
library(Boruta)       # Selection of important features for RF
library(parallel)
library(MFSIS)
library(reshape)
(core.num <- detectCores())
DF.Gen <- function(n, p, mod){
# Models from Duroux and Scornet (2018)
{
if(mod < 3){
dependt.Cov = matrix(c(1, 0.3, 0.3, 0.6, 0.6,
0.3, 1, 0.3, 0.2, 0.1,
0.3, 0.3, 1, 0.2, 0.1,
0.6, 0.2, 0.2, 1, 0.1,
0.6, 0.1, 0.1, 0.1, 1), nrow = 5, byrow = TRUE)
Zero.Mat = matrix(0, nrow = 5, ncol = p-5)
Sig = rbind(cbind(dependt.Cov, Zero.Mat), cbind(t(Zero.Mat), diag(p-5)))
# Main effects only
X.m1 = SimDesign::rmvnorm(n, mean = rep(0, p), sigma = Sig)
colnames(X.m1) = paste0("X", 1:p)
# Interaction effects
id1 = unlist(sapply(1:p, function(x) x:p))
id2 = rep(1:p, p:1)
X.i = sapply(1:length(id1), function(x) X.m1[, id2[x]]*X.m1[, id1[x]])
colnames(X.i) = sapply(1:length(id1), function(x) paste0("X", id2[x], "X", id1[x]))
X = cbind(X.m1, X.i)
}
else{
X.m2 = matrix(runif(n*p), nrow = n, ncol = p)
colnames(X.m2) = paste0("X", 1:p)
# Standardization (Mean Clustering)
X.m2 = apply(X.m2, 2, scale, scale = FALSE) # The quadratic term of a centered variable can avoid collinearity
# Interaction effects
id1 = unlist(sapply(1:p, function(x) x:p))
id2 = rep(1:p, p:1)
X.i = sapply(1:length(id1), function(x) X.m2[, id2[x]]*X.m2[, id1[x]])
colnames(X.i) = sapply(1:length(id1), function(x) paste0("X", id2[x], "X", id1[x]))
X = cbind(X.m2, X.i)
Xt = 2*(X - 0.5)
}
}
# Models from Jain and Xu (2021)
if (mod==1){
Y = 1 + 0.2*X[,1] + 0.3*X[,2] + 0.4*X[,3] + 0.3*X[,1]*X[,2] + rnorm(n, mean = 0, sd = sqrt(.25))
}
if (mod==2){
Y = 1 + 0.4*X[,3] + 0.3*X[,1]*X[,2] + rnorm(n,mean = 0, sd = sqrt(0.25))
}
if (mod==3){
Y = 1 + 0.4*X[,3] + 0.3*(X[,1]>0.5 & X[,2]>0.5) + rnorm(n, mean = 0, sd = sqrt(.25))
}
if (mod==4){
Y = 1 + 0.2*X[,1] + 0.3*X[,2] + 0.3*X[,1]*X[,2] + 0.3*(X[,3]>0.5 & X[,4]>0.5) + rnorm(n, mean = 0, sd = sqrt(.25))
}
Dat = data.frame(cbind(Y, X))
# colnames(Dat) = c("Y", paste0("x", 1:p))
return(Dat)
}
n = 500
p = 500
n.val <- 500
p.val <- 500
mod <- 1
iter <- 1
DF <- DF.Gen(n,p,mod)
## SCREENING
DCSIS.func <- function(n, p, mod){
DF.X <- as.matrix(DF[,-1])
DF.Y <- as.vector(DF[,1])
DCSIS.mod <- MFSIS(X = DF.X, Y = DF.Y, nsis = n/log(n)*log((p*(p+1))/2), method = "DCSIS")
return(DCSIS.mod)
}
set.seed(1788)
DCSIS_iter <- list(replicate(iter, DCSIS.func(n = n.val, p = p.val, mod = mod)))
DCSIS_iter
us_adults <- tibble(
climate_change_affects = c(rep("Yes", 62000), rep("No", 38000)))
n <- 60
samp <- us_adults %>%
sample_n(size = n)
prop_test(samp,
climate_change_affects ~ NULL,
success = "Yes",
z = TRUE,
conf_int = TRUE,
conf_level = 0.90, correct = FALSE)
library(tidyverse)
library(openintro)
library(infer)
us_adults <- tibble(
climate_change_affects = c(rep("Yes", 62000), rep("No", 38000)))
n <- 60
samp <- us_adults %>%
sample_n(size = n)
prop_test(samp,
climate_change_affects ~ NULL,
success = "Yes",
z = TRUE,
conf_int = TRUE,
conf_level = 0.90, correct = FALSE)
library(tidyverse)
library(openintro)
library(MASS)
library(readr)
library(learnr)
library(ggplot2)
library(gradethis) #remotes::install_github("rstudio/gradethis")
library(learnrhash) #devtools::install_github("rundel/learnrhash")
library(gapminder)
library(emo) #devtools::install_github("hadley/emo")
library(png)
library(grid)
tutorial_options(exercise.timelimit = 120,
exercise.checker = gradethis::grade_learnr)
gradethis_setup(exercise.reveal_solution = FALSE)
library(infer)
?infer
?infer
library(pacman)
setwd("C:/Users/13363/OneDrive - North Carolina A & T State University/TIP-GRA/Shiny Labs/CL7b_Inference_Categorical_Data")
