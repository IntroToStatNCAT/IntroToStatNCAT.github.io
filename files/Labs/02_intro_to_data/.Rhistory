boot.iqr.mc = c()
for(i in 1:B){
x = sample(y, n, replace = T)
boot.iqr.mc[i] = IQR(x)
}
boot.se.mc = sd(boot.iqr.mc)
jack.iqr.mc = c()
for(j in 1:n){
x = y[-j]
jack.iqr.mc[j] = IQR(x)
}
jack.se.mc = sqrt((n-1)/n*sum((jack.iqr.mc-mean(jack.iqr.mc))^2))
d = data.frame(SE = c(boot.se.mc, jack.se.mc),
True_SE = rep(exact.se,2),
Absolute_difference = c(abs(boot.se.mc-exact.se),
abs(jack.se.mc-exact.se)),
row.names = c("Bootstrap","Jackknife"))
d
set.seed(105)
exact.se = 0.1089
n = 100
y = rexp(n , rate = 1.5)
B = 1000
boot.iqr.mc = c()
for(i in 1:B){
x = sample(y, n, replace = T)
boot.iqr.mc[i] = IQR(x)
}
boot.se.mc = sd(boot.iqr.mc)
jack.iqr.mc = c()
for(j in 1:n){
x = y[-j]
jack.iqr.mc[j] = IQR(x)
}
jack.se.mc = sqrt((n-1)/n*sum((jack.iqr.mc-mean(jack.iqr.mc))^2))
d = data.frame(SE = c(boot.se.mc, jack.se.mc),
True_SE = rep(exact.se,2),
Absolute_difference = c(abs(boot.se.mc-exact.se),
abs(jack.se.mc-exact.se)),
row.names = c("Bootstrap","Jackknife"))
d
set.seed(105)
exact.se = 1.633*sqrt(1/(1000*1.5^2)) #0.1089
n = 1000
y = rexp(n , rate = 1.5)
B = 1000
boot.iqr.mc = c()
for(i in 1:B){
x = sample(y, n, replace = T)
boot.iqr.mc[i] = IQR(x)
}
boot.se.mc = sd(boot.iqr.mc)
jack.iqr.mc = c()
for(j in 1:n){
x = y[-j]
jack.iqr.mc[j] = IQR(x)
}
jack.se.mc = sqrt((n-1)/n*sum((jack.iqr.mc-mean(jack.iqr.mc))^2))
d = data.frame(SE = c(boot.se.mc, jack.se.mc),
True_SE = rep(exact.se,2),
Absolute_difference = c(abs(boot.se.mc-exact.se),
abs(jack.se.mc-exact.se)),
row.names = c("Bootstrap","Jackknife"))
d
install.packages("tensorflow")
install_tensorflow(version = "nightly-gpu")
library(tensorflow)
install_tensorflow(version = "nightly-gpu")
n
install.packages("keras")
library(tensorflow)
library(keras)
mnist = dataset_mnist()
library(tensorflow)
library(keras)
mnist = dataset_mnist()
install.packages("keras")
library(tensorflow)
library(keras)
mnist = dataset_mnist()
install_tensorflow()
library(tensorflow)
library(keras)
mnist = dataset_mnist()
install_tensorflow()
install_tensorflow()
library(tensorflow)
library(keras)
library(keras)
install_tensorflow()
delete.response(d)
d
rm(d)
x = 1
y = 1
z = 1
rm(c(x,y,z))
rm(c("x","y","z"))
rm(x)
rm(y)
rm(z)
1:10*2:11
1:10%*%2:11
sum(1:10*2:11)
b = function(x){
n <- x+2
sum(x)
}
b(1:10)
b = function(x){
n <<- x+2
sum(x)
}
b(1:10)
b = function(x){
n <- x+2
sum(x)
}
b(1:10)
b = function(x){
n <<- x+2
sum(x)
}
b(1:10)
b = function(x){
n <<- x+2
sum(x)
}
b(1:10)
b = function(x){
n <<- x+2
(n+2)^2
}
b(1:5)
b = function(x){
n <- x+2
(n+2)^2
}
b(1:5)
(n+2)^2
b = function(x){
n <- x+2
(n+2)^2
}
b(1:5)
(n+2)^2
b = function(x){
n <<- x+2
(n+2)^2
}
b(1:5)
(n+2)^2
library(tidyverse)
library(ggplot2)
EuStockMarkets_tidy <- as.data.frame(EuStockMarkets) %>% gather(key="index", value="closing_price")
head(EuStockMarkets_tidy)
library(tidyverse)
library(ggplot2)
EuStockMarkets_tidy <- as.data.frame(EuStockMarkets) %>% gather(key="index", value="closing_price")
head(EuStockMarkets_tidy)
View(EuStockMarkets_tidy)
rep(1:nrow(EuStockMarkets),4)
dat = EuStockMarkets_tidy%>%
mutate(n = rep(1:nrow(EuStockMarkets),4))
names(EuStockMarkets_tidy)
dat %>%
ggplot(aes(x=n,y=closing_price,col=index))+
geom_line()
library(tidyverse)
library(ggplot2)
EuStockMarkets_tidy <- as.data.frame(EuStockMarkets) %>% gather(key="index", value="closing_price")%>%
mutate(n = rep(1:nrow(EuStockMarkets),4))
EuStockMarkets_tidy%>%
ggplot(aes(x=n,y=closing_price,col=index))+
geom_line()
rep(1:5,1:3)
rep(1:5,3)
rep(1:5,rep(1,3))
rep(1:5,rep(3,5))
rep(1:5,rep(3,3))
rep(1:5,rep(3,5))
rep(1:5,rep(5,3))
rep(1:5,rep(5,5))
library(ggplot2)
ggplot(mpg, aes(displ, hwy, colour = class)) +
geom_point()
plot(mpg)
attach(mpg)
plot(displ, hwy)
library(ggplot2)
ggplot(mpg, aes(displ, hwy, colour = class)) +
geom_point()
ggplot(mpg, aes(displ, hwy, colour = class)) +
geom_point(size=2)
ggplot(mpg, aes(displ, hwy, colour = class)) +
geom_line(size=2)
ggplot(mpg, aes(displ, hwy, colour = class)) +
geom_point(size=2)
install.packages("tidytext")
library(tidytext)
library(tidyverse)
x = "I love pancakes. I love dogs. I love cats. I hate rats."
x %>%
unnest_tokens(word,text)
x %>%
unnest_tokens(word,x)
x %>%
unnest_tokens(word,x)
unnest_tokens(word,x)
?unnest_tokens
text <- c("Because I could not stop for Death -",
"He kindly stopped for me -",
"The Carriage held but just Ourselves -",
"and Immortality")
text_df <- tibble(line = 1:4, text = text)
text_df %>%
unnest_tokens(word,text)
library(readr)
shootings_killings <- read_csv("C:/Users/arbaa/Desktop/shootings_killings.csv")
View(shootings_killings)
names(shootings_killings)
x = shootings_killings%>%
select(`A brief description of the circumstances surrounding the death`)
x_df = tibble(line = 1:nrow(x), text = `A brief description of the circumstances surrounding the death`)
View(x)
x_df = tibble(line = 1:nrow(x), text = x)
View(x_df)
x_df = tibble(text = x)
View(x_df)
x_df %>%
unnest_tokens(word, text)
x_df = tibble(line = 1:nrow(x), text = x)
x_df %>%
unnest_tokens(word, text)
View(x_df)
names(x_df)[2] = c("text")
View(x_df)
colnames(x_df)[2] = c("text")
View(x_df)
x_df = tibble(text = x)
colnames(x_df) = c("text")
x = shootings_killings%>%
select(`A brief description of the circumstances surrounding the death`)
x_df = tibble(x)
colnames(x_df) = c("text")
x_df %>%
unnest_tokens(word, text)
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)
library(ggplot2)
install.packages("wordcloud")
library(wordcloud)
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
count(word)%>%
with(wordcloud(word,n))
clean = x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)
clean = x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
count(word)
View(clean)
View(shootings_killings)
x = shootings_killings%>%
select(`A brief description of the circumstances surrounding the death`, Race)
x_df = tibble(x)
View(x_df)
colnames(x_df)[1] = c("text")
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
count(word, sort = TRUE)%>%
mutate(word = reorder(word,n))%>%
ggplot(aes(n, word))+
geom_col()+
facet_wrap(~Race)
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
count(word, sort = TRUE)%>%
mutate(word = reorder(word,n))%>%
ggplot(aes(n, word))+
geom_col()+
facet_wrap(.~Race)
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
count(word, sort = TRUE)%>%
mutate(word = reorder(word,n))
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
count(word, sort = TRUE)%>%
mutate(word = reorder(word,n))%>%
ungroup()
x_df %>%
unnest_tokens(word, text)
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
group_by(Race)%>%
count(word, sort = TRUE)%>%
mutate(word = reorder(word,n))%>%
ggplot(aes(n, word))+
geom_col()+
facet_wrap(.~Race)
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
group_by(Race)%>%
count(word, sort = TRUE)%>%
mutate(word = reorder(word,n))%>%
ggplot(aes(n, word))+
geom_col()+
facet_wrap(~Race)
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
group_by(Race)%>%
count(word, sort = TRUE)%>%
mutate(word = reorder(word,n))%>%
ggplot(aes(n, word))+
geom_col()+
facet_wrap(~Race)
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
group_by(Race)%>%
count(word, sort = TRUE)
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
group_by(Race)%>%
count(word, sort = TRUE)%>%
filter(n>450)%>%
ggplot(aes(n, word))+
geom_col()+
facet_wrap(~Race)
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
group_by(Race)%>%
count(word, sort = TRUE)%>%
filter(n>400)%>%
ggplot(aes(n, word))+
geom_col()+
facet_wrap(~Race)
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
group_by(Race)%>%
count(word, sort = TRUE)%>%
filter(n>300)%>%
ggplot(aes(n, word))+
geom_col()+
facet_wrap(~Race)
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
group_by(Race)%>%
count(word, sort = TRUE)%>%
filter(n>300)%>%
ggplot(aes(n, word))+
geom_col()+
facet_wrap(~Race, scales = "free")+
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
group_by(Race)%>%
count(word, sort = TRUE)%>%
filter(n>300)%>%
ggplot(aes(n, word))+
geom_col()+
facet_wrap(~Race, scales = "free")
table(x_df$Race)
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
group_by(Race)%>%
count(word, sort = TRUE)%>%
ggplot(aes(n, word))+
geom_col()+
facet_wrap(~Race, scales = "free")
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
group_by(Race)%>%
count(word, sort = TRUE)%>%
filter(n>100)%>%
ggplot(aes(n, word))+
geom_col()+
facet_wrap(~Race, scales = "free")
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
group_by(Race)%>%
count(word, sort = TRUE)%>%
filter(n>200)%>%
ggplot(aes(n, word))+
geom_col()+
facet_wrap(~Race, scales = "free")
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
group_by(Race)%>%
count(word, sort = TRUE)%>%
na.omit()%>%
filter(n>200)%>%
ggplot(aes(n, word))+
geom_col()+
facet_wrap(~Race, scales = "free")
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
group_by(Race)%>%
count(word, sort = TRUE)%>%
mutate(word = reorder(word, n)) %>%
na.omit()%>%
filter(n>200)%>%
ggplot(aes(n, word))+
geom_col()+
facet_wrap(~Race, scales = "free")
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
group_by(Race)%>%
count(word, sort = TRUE)%>%
mutate(word = reorder(word, n)) %>%
na.omit()%>%
filter(n>200, Race != "W")%>%
ggplot(aes(n, word))+
geom_col()+
facet_wrap(~Race, scales = "free")
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
group_by(Race)%>%
count(word, sort = TRUE)%>%
mutate(word = reorder(word, n)) %>%
na.omit()%>%
filter(n>50, Race != "W")%>%
ggplot(aes(n, word))+
geom_col()+
facet_wrap(~Race, scales = "free")
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
group_by(Race)%>%
count(word, sort = TRUE)%>%
mutate(word = reorder(word, n)) %>%
na.omit()%>%
filter(n>50, Race !%in% c("W","B","H"))%>%
ggplot(aes(n, word))+
geom_col()+
facet_wrap(~Race, scales = "free")
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
group_by(Race)%>%
count(word, sort = TRUE)%>%
mutate(word = reorder(word, n)) %>%
na.omit()%>%
filter(n>50, Race %in% !c("W","B","H"))%>%
ggplot(aes(n, word))+
geom_col()+
facet_wrap(~Race, scales = "free")
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
group_by(Race)%>%
count(word, sort = TRUE)%>%
mutate(word = reorder(word, n)) %>%
na.omit()%>%
filter(n>50, Race %in% -c("W","B","H"))%>%
ggplot(aes(n, word))+
geom_col()+
facet_wrap(~Race, scales = "free")
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
group_by(Race)%>%
count(word, sort = TRUE)%>%
mutate(word = reorder(word, n)) %>%
na.omit()%>%
filter(Race %in% c("A","N","O"))%>%
ggplot(aes(n, word))+
geom_col()+
facet_wrap(~Race, scales = "free")
x_df %>%
unnest_tokens(word, text)%>%
anti_join(stop_words)%>%
group_by(Race)%>%
count(word, sort = TRUE)%>%
mutate(word = reorder(word, n)) %>%
na.omit()%>%
filter(n > 10, Race %in% c("A","N","O"))%>%
ggplot(aes(n, word))+
geom_col()+
facet_wrap(~Race, scales = "free")
setwd("D:\A&T\GRA\OpenIntro Statistics material\Labs\02_intro_to_data")
setwd("D: \A&T\GRA\OpenIntro Statistics material\Labs\02_intro_to_data")
setwd("D://A&T//GRA//OpenIntro Statistics material//Labs//02_intro_to_data")
setwd("D://A&T//GRA//OpenIntro Statistics material//Labs//02_intro_to_data")
setwd("~/")
setwd("D://A&T//GRA//OpenIntro Statistics material//Labs//02_intro_to_data")
