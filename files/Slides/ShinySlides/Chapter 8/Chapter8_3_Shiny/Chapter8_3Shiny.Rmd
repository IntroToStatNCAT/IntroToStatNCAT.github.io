---
title: "Chapter 8"
subtitle: "Introduction to Linear Regression"
output: 
  ioslides_presentation:
    progressive: FALSE
    smaller: yes
    widescreen: yes
    transition: "faster"

runtime: shiny_prerendered
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, echo=F, message=F, warning=F}
library(datasets)
library(tidyverse)
library(shiny)
library(xtable)
library(faraway)
library(here)
library(broom)
library(scales)
library(jpeg)
library(openintro)
library(learnr)
library(readr)
library(knitr)
library(png)
library(gradethis) #remotes::install_github("rstudio/gradethis")
library(learnrhash) #devtools::install_github("rundel/learnrhash")
library(grid)
library(GGally)
library(tinytex)
data(COL)
```


## Acknowledgement

<center>
<div class="black">
These notes use content from OpenIntro Statistics Slides by   

Mine Cetinkaya-Rundel.
</div>
</center>


# Types of outliers in linear regression

## Types of outliers

<div class="black">

<div style="float: left; width: 50%;">
<div class="red">
How do outliers influence the least squares in this plot?
</div>

To answer this question think of where the regression line would be with and without the outlier(s). Without the outliers the regression line would be steeper, and lie closer to the larger group of observations. With the outliers the line is pulled up and away from some of the observations in the larger group. 
</div>


<div style="float: right; width: 50%;">
```{r, echo=F, message=F, warning=F, out.width="100%",fig.align='center'}
set.seed(238)

n <- c(50, 25, 78, 55, 70, 150)
m <- c(12, -4, 7, -19, 0, 40)
xr <- list(0.3, c(2), 1.42,
	runif(4,1.45,1.55), 5.78, -0.6)
yr <- list(-4, c(-8), 19,
	c(-17,-20,-21,-19), 12, -23.2)
i = 4
x <- runif(n[i])
y <- m[i]*x + rnorm(n[i])
x <- c(x,xr[[i]])
y <- c(y,yr[[i]])
par(mar=c(4,4,1,1), las=1, mgp=c(2.5,0.5,0), cex.lab = 1.25, cex.axis = 2, mfrow = c(2,1))
lmPlot(x, y, col = COL[1,2], lCol = COL[4], lwd = 3, cex = 2)

```
</div>
</div>



## Types of outliers
<div class="black">

<div style="float: left; width: 50%;">
<div class= "red">
How do outliers influence the least squares in this plot?
</div>
</div>


<div style="float: right; width: 50%;">

```{r, echo=F, message=F, warning=F, out.width="100%",fig.align='center'}
set.seed(238)

n <- c(50, 25, 78, 55, 70, 150)
m <- c(12, -4, 7, -19, 0, 40)
xr <- list(0.3, c(2), 1.42,
	runif(4,1.45,1.55), 5.78, -0.6)
yr <- list(-4, c(-8), 19,
	c(-17,-20,-21,-19), 12, -23.2)
i = 5
x <- runif(n[i])
y <- m[i]*x + rnorm(n[i])
x <- c(x,xr[[i]])
y <- c(y,yr[[i]])
par(mar=c(4,4,1,1), las=1, mgp=c(2.5,0.5,0), cex.lab = 1.25, cex.axis = 2, mfrow = c(2,1))
lmPlot(x, y, col = COL[1,2], lCol = COL[4], lwd = 3, cex = 2)

```
</div>
</div>



## Types of outliers
<div class="black">

<div style="float: left; width: 50%;">
<div class= "red">
How do outliers influence the least squares in this plot?
</div>

Without the outlier there is no evident relationship between $x$ and $y$.
</div>


<div style="float: right; width: 50%;">
```{r, echo=F, message=F, warning=F, out.width="100%",fig.align='center'}
set.seed(238)

n <- c(50, 25, 78, 55, 70, 150)
m <- c(12, -4, 7, -19, 0, 40)
xr <- list(0.3, c(2), 1.42,
	runif(4,1.45,1.55), 5.78, -0.6)
yr <- list(-4, c(-8), 19,
	c(-17,-20,-21,-19), 12, -23.2)
i = 5
x <- runif(n[i])
y <- m[i]*x + rnorm(n[i])
x <- c(x,xr[[i]])
y <- c(y,yr[[i]])
par(mar=c(4,4,1,1), las=1, mgp=c(2.5,0.5,0), cex.lab = 1.25, cex.axis = 2, mfrow = c(2,1))
lmPlot(x, y, col = COL[1,2], lCol = COL[4], lwd = 3, cex = 2)

```
</div>
</div>



## Some terminology
<div class="black">
- **Outliers** are points that lie away from the cloud of points.


- Outliers that lie horizontally away from the center of the cloud are called **high leverage** points.


- High leverage points that actually influence the $\underline{\text{slope}}$ of the regression line are called **influential** points.


- In order to determine if a point is influential, visualize the regression line with and without the point. Does the slope of the line change considerably? If so, then the point is influential. If not, then it's not an influential point. 

</div>


## Influential points
<div class="black">
Data are available on the log of the surface temperature and the log of the light intensity of 47 stars in the star cluster CYG OB1.

<div style="float: left; width: 50%;">
```{r, echo=F, message=F, warning=F, out.width="100%",fig.align='center'}
data(star)

par(mar=c(4,4,2,1), las=1, mgp=c(2.5,0.7,0), cex.lab = 2, cex.axis = 2)

plot(light ~ temp, data = star, pch=19, cex = 2, col=COL[1,2], xlab = "log(temp)", ylab = "log(light intensity)")

abline(lm(light[temp>4]~temp[temp>4], data = star), col = COL[4], lwd = 3)
abline(lm(light~temp, data = star), col = COL[2], lwd = 3, lty = 2)

legend("top", inset = 0.05, c("w/ outliers","w/o outliers"), lty = c(2,1), lwd = c(2,3), col = c(COL[2],COL[4]), cex = 2)

```
</div>


<div style="float: right; width: 50%;">

```{r, out.width="100%"}
cy <- readPNG("cyg.png")
grid.raster(cy)

```
</div>
</div>




## Types of outliers
<div class="black">
<div style="float: left; width: 50%;">
<div class="red">
Which of the below best describes the outlier?
</div>

A) Influential

B) High Leverage

C) None of the above

D) There are no outliers
</div>

<div style="float: right; width: 50%;">

```{r, echo=F, message=F, warning=F, out.width="100%",fig.align='center'}
set.seed(238)

n <- c(50, 25, 78, 55, 70, 150)
m <- c(12, -4, 7, -19, 0, 40)
xr <- list(0.3, c(2), 1.42,
	runif(4,1.45,1.55), 5.78, -0.6)
yr <- list(-4, c(-8), 19,
	c(-17,-20,-21,-19), 12, -23.2)
i = 6
x <- runif(n[i])
y <- m[i]*x + rnorm(n[i])
x <- c(x,xr[[i]])
y <- c(y,yr[[i]])
par(mar=c(4,4,1,1), las=1, mgp=c(2.5,0.5,0), cex.lab = 1.25, cex.axis = 2, mfrow = c(2,1))
lmPlot(x, y, col = COL[1,2], lCol = COL[4], lwd = 3, cex = 2)
```

</div>
</div>


## Types of outliers
<div class="black">
<div style="float: left; width: 50%;">
<div class="red">
Which of the below best describes the outlier?
</div>

A) Influential

B) <div class="red">High Leverage</div>

C) None of the above

D) There are no outliers
</div>

<div style="float: right; width: 50%;">

```{r, echo=F, message=F, warning=F, out.width="100%",fig.align='center'}
set.seed(238)

n <- c(50, 25, 78, 55, 70, 150)
m <- c(12, -4, 7, -19, 0, 40)
xr <- list(0.3, c(2), 1.42,
	runif(4,1.45,1.55), 5.78, -0.6)
yr <- list(-4, c(-8), 19,
	c(-17,-20,-21,-19), 12, -23.2)
i = 6
x <- runif(n[i])
y <- m[i]*x + rnorm(n[i])
x <- c(x,xr[[i]])
y <- c(y,yr[[i]])
par(mar=c(4,4,1,1), las=1, mgp=c(2.5,0.5,0), cex.lab = 1.25, cex.axis = 2, mfrow = c(2,1))
lmPlot(x, y, col = COL[1,2], lCol = COL[4], lwd = 3, cex = 2)
```

</div>
</div>



## Types of outliers
<div class="black">
<div style="float: left; width: 50%;">
<div class="red">
Does this outlier influence the slope of the regression line?
</div>
</div>

<div style="float: right; width: 50%;">

```{r, echo=F, message=F, warning=F, out.width="100%",fig.align='center'}
set.seed(238)

n <- c(50, 25, 78, 55, 70, 150)
m <- c(12, -4, 7, -19, 0, 40)
xr <- list(0.3, c(2), 1.42,
	runif(4,1.45,1.55), 5.78, -0.6)
yr <- list(-4, c(-8), 19,
	c(-17,-20,-21,-19), 12, -23.2)
i = 6
x <- runif(n[i])
y <- m[i]*x + rnorm(n[i])
x <- c(x,xr[[i]])
y <- c(y,yr[[i]])
par(mar=c(4,4,1,1), las=1, mgp=c(2.5,0.5,0), cex.lab = 1.25, cex.axis = 2, mfrow = c(2,1))
lmPlot(x, y, col = COL[1,2], lCol = COL[4], lwd = 3, cex = 2)
```

</div>
</div>



## Types of outliers
<div class="black">
<div style="float: left; width: 50%;">
<div class="red">
Does this outlier influence the slope of the regression line?

Not much...
</div>
</div>

<div style="float: right; width: 50%;">

```{r, echo=F, message=F, warning=F, out.width="100%",fig.align='center'}
set.seed(238)

n <- c(50, 25, 78, 55, 70, 150)
m <- c(12, -4, 7, -19, 0, 40)
xr <- list(0.3, c(2), 1.42,
	runif(4,1.45,1.55), 5.78, -0.6)
yr <- list(-4, c(-8), 19,
	c(-17,-20,-21,-19), 12, -23.2)
i = 6
x <- runif(n[i])
y <- m[i]*x + rnorm(n[i])
x <- c(x,xr[[i]])
y <- c(y,yr[[i]])
par(mar=c(4,4,1,1), las=1, mgp=c(2.5,0.5,0), cex.lab = 1.25, cex.axis = 2, mfrow = c(2,1))
lmPlot(x, y, col = COL[1,2], lCol = COL[4], lwd = 3, cex = 2)
```

</div>
</div>



## Recap
<div class="black">
<div class="red">
Which of following is $\underline{true}$?
</div>

A) Influential points always change the intercept of the regression line.

B) Influential points always reduce $R^2$.

C) It is much more likely for a low leverage point to be influential, than a high leverage point.

D) When the data set includes an influential point, the relationship between the explanatory variable and the response variable is always nonlinear.

E) None of the above.
</div>


## Recap
<div class="black">
<div class="red">
Which of following is $\underline{true}$?
</div>

A) Influential points always change the intercept of the regression line.

B) Influential points always reduce $R^2$.

C) It is much more likely for a low leverage point to be influential, than a high leverage point.

D) When the data set includes an influential point, the relationship between the explanatory variable and the response variable is always nonlinear.

E) <div class="red"> None of the above.
</div>
</div>



## Recap
<div class="black">
<div style="float: left; width: 50%;">

<center>
$R = 0.08, R^2 = 0.0064$
</center>
</div>

<div style="float: right; width: 50%;">
```{r, echo=F, message=F, warning=F, out.width="100%",fig.align='center'}
set.seed(238)

n <- c(50, 25, 78, 55, 70, 150)
m <- c(12, -4, 7, -19, 0, 40)
xr <- list(0.3, c(2), 1.42,
	runif(4,1.45,1.55), 5.78, -0.6)
yr <- list(-4, c(-8), 19,
	c(-17,-20,-21,-19), 12, -23.2)
i = 5
x <- runif(n[i])
y <- m[i]*x + rnorm(n[i])
x <- c(x,xr[[i]])
y <- c(y,yr[[i]])
par(mar=c(4,4,1,1), las=1, mgp=c(2.5,0.5,0), cex.lab = 2, cex.axis = 2, mfrow = c(2,1))
lmPlot(x, y, col = COL[1,2], lCol = COL[4], lwd = 3, cex = 2)

```

</div>
</div>


## Recap
<div class="black">
<div style="float: left; width: 50%;">

<center>
$R = 0.79, R^2 = 0.6241$
</center>
</div>

<div style="float: right; width: 50%;">

```{r, echo=F, message=F, warning=F, out.width="100%",fig.align='center'}
set.seed(238)

n <- c(50, 25, 78, 55, 70, 150)
m <- c(12, -4, 7, -19, 0, 40)
xr <- list(0.3, c(2), 1.42,
	runif(4,1.45,1.55), 5.78, -0.6)
yr <- list(-4, c(-8), 19,
	c(-17,-20,-21,-19), 12, -23.2)
i = 5
x <- runif(n[i])
y <- m[i]*x + rnorm(n[i])
x <- c(x,xr[[i]])
y <- c(y,yr[[i]])
par(mar=c(4,4,1,1), las=1, mgp=c(2.5,0.5,0), cex.lab = 2, cex.axis = 2, mfrow = c(2,1))
lmPlot(x[1:70], y[1:70], col = COL[1,2], lCol = COL[4], cex = 2,lwd = 3, xlim = range(x), ylim = range(y))
#abline(temp, lty = 3)
```

</div>
</div>
