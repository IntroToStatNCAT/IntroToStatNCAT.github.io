![](images/lesson3_img1.png)
?prnorm
?pnorm
2*pnorm(-8.125, lower.tail = T)
2*pnorm(-8.125, lower.tail = TRUE)
pnorm(-8.125, lower.tail = TRUE) + pnorm(8.125, lower.tail = FALSE)
pnorm(3.85, lower.tail = T)
pnorm(3.85, lower.tail = F)
2*pnorm(3.85, lower.tail = F)
0.06/0.0156
2*pnorm(3.846154, lower.tail = F)
2*pnorm(-3.846154, lower.tail = T)
0.06/0.0156
pnorm(-3.846154, lower.tail = T)
install.packages("kableExtra")
library(kableExtra)
c("Survived" = c(11,14,25),"Died"=c(39,26,50),"Total"=C(50,40,90))
c("Survived" = c(11,14,25),"Died"=c(39,26,50),"Total"=c(50,40,90))
cbind("Survived" = c(11,14,25),"Died"=c(39,26,50),"Total"=c(50,40,90))
dat = as.data.frame(cbind("Survived" = c(11,14,25),"Died"=c(39,26,50),"Total"=c(50,40,90)))
rownames(dat) = c("Control","Treatment","Total")
523/785
#knitr::opts_chunk$set(eval = FALSE)
library(dplyr)
library(ggplot2)
library(learnr)
library(gradethis) #remotes::install_github("rstudio/gradethis")
library(learnrhash) #devtools::install_github("rundel/learnrhash")
tutorial_options(exercise.timelimit = 60, exercise.checker = gradethis::grade_learnr)
#knitr::opts_chunk$set(eval = FALSE)
2*pnorm(-0.22, lower.tail = T)
2*pnorm(-0.22, lower.tail = T)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(learnr)
library(broom)
library(knitr)
library(infer)
library(emo)
library(openintro)
library(gradethis) #remotes::install_github("rstudio/gradethis")
library(learnrhash) #devtools::install_github("rundel/learnrhash")
# data prep --------------------------------------------------------------------
# load data
gss <- read.csv(url("https://raw.githubusercontent.com/IntroToStatNCAT/Lab_FoundationsForInference/main/gss-sampled.csv"))
gss2016 <- read.csv(url("https://raw.githubusercontent.com/IntroToStatNCAT/Lab_FoundationsForInference/main/gss-sampled-2016.csv"))
gss2016_small <- read.csv(url("https://raw.githubusercontent.com/IntroToStatNCAT/Lab_FoundationsForInference/main/gss2016-n50.csv"))
gss2016_smaller <- read.csv(url("https://raw.githubusercontent.com/IntroToStatNCAT/Lab_FoundationsForInference/main/gss2016-n10.csv"))
#knitr::opts_chunk$set(eval = FALSE)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(learnr)
library(broom)
library(knitr)
library(infer)
library(emo)
library(openintro)
library(gradethis) #remotes::install_github("rstudio/gradethis")
library(learnrhash) #devtools::install_github("rundel/learnrhash")
# data prep --------------------------------------------------------------------
# load data
gss <- read.csv(url("https://raw.githubusercontent.com/IntroToStatNCAT/Lab_FoundationsForInference/main/gss-sampled.csv"))
gss2016 <- read.csv(url("https://raw.githubusercontent.com/IntroToStatNCAT/Lab_FoundationsForInference/main/gss-sampled-2016.csv"))
gss2016_small <- read.csv(url("https://raw.githubusercontent.com/IntroToStatNCAT/Lab_FoundationsForInference/main/gss2016-n50.csv"))
gss2016_smaller <- read.csv(url("https://raw.githubusercontent.com/IntroToStatNCAT/Lab_FoundationsForInference/main/gss2016-n10.csv"))
```{r setup, include=FALSE}
#knitr::opts_chunk$set(eval = FALSE)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(learnr)
library(broom)
library(knitr)
library(infer)
library(emo)
library(openintro)
library(gradethis) #remotes::install_github("rstudio/gradethis")
library(learnrhash) #devtools::install_github("rundel/learnrhash")
# data prep --------------------------------------------------------------------
# load data
gss <- read.csv(url("https://raw.githubusercontent.com/IntroToStatNCAT/RA_FoundationsForInference/main/gss-sampled.csv"))
gss2016 <- read.csv(url("https://raw.githubusercontent.com/IntroToStatNCAT/RA_FoundationsForInference/main/gss-sampled-2016.csv"))
gss2016_small <- read.csv(url("https://raw.githubusercontent.com/IntroToStatNCAT/RA_FoundationsForInference/main/gss2016-n50.csv"))
gss2016_smaller <- read.csv(url("https://raw.githubusercontent.com/IntroToStatNCAT/RA_FoundationsForInference/main/gss2016-n10.csv"))
gss <- read.csv(url("https://raw.githubusercontent.com/IntroToStatNCAT/RA_ForInference/main/gss-sampled.csv"))
gss <- read.csv(url("https://raw.githubusercontent.com/IntroToStatNCAT/R_FoundationsForInference/main/gss-sampled.csv"))
gss <- read.csv(url("https://raw.githubusercontent.com/IntroToStatNCAT/Lab_FoundationsForInference/main/gss-sampled.csv"))
gss <- read.csv(url("https://raw.githubusercontent.com/IntroToStatNCAT/RA_FoundationsForInference/main/gss-sampled.csv"))
sqrt(0.5*0.5/1000)
SE = sqrt(0.56*(1-0.56)/1028)
z = (0.56 - 0.5)/SE
2*pnorm(z, lower.tail = F)
pnorm(z, lower.tail = F)
SE = sqrt(0.5*(1-0.5)/1028)
z = (0.5 - 0.56)/SE
2*pnorm(z, lower.tail = F)
2*pnorm(z, lower.tail = T)
z = (0.56 - 0.50)/SE
2*pnorm(z, lower.tail = F)
SE = 0.0156
z = (0.56 - 0.50)/SE
2*pnorm(z, lower.tail = F)
N1 = 460
P1 = 414/N1
N2 = 438
P2 = 387/N2
PHAT = (P1-P2)
SE = sqrt(P1*(1-P1)/N1 + P2*(1-P2)/N2)
Z= qnorm(1.99/2)
Z*SE
Z= qnorm(1.99/2)
Z
Z= qnorm((2-0.01)/2)
Z
Z= qnorm(0.99, lower.tail = F)
Z
Z= qnorm(0.99)
Z
Z*SE
N1 = 511
P1 = 351/N1
N2 = 470
P2 = 296/N2
PHAT = P1-P2
SE= sqrt(P1*(1-P1)/N1+P2*(1-P2)/N2)
Z = (P1-P2)/SE
Z
qnorm(1.9/2)
qnorm((2-0.1)/2)
qnorm(0.9)
alpha = 0.01
qnorm(1-alpha)
alpha = 0.1
qnorm(1-alpha)
alpha = 0.1
qnorm(1-alpha)
N1 = 511
P1 = 351/N1
N2 = 470
P2 = 296/N2
PHAT = P1-P2
SE= sqrt(P1*(1-P1)/N1+P2*(1-P2)/N2)
Z = (P1-P2)/SE
Z
N1 = 460
P1 = 414/N1
N2 = 438
P2 = 387/N2
PHAT = P1-P2
SE= sqrt(P1*(1-P1)/N1+P2*(1-P2)/N2)
Z = (P1-P2)/SE
Z
alpha = 0.01
qnorm(1-alpha)
N1 = 460
P1 = 414/N1
N2 = 438
P2 = 387/N2
PHAT = P1-P2
SE= sqrt(P1*(1-P1)/N1+P2*(1-P2)/N2)
Z = (P1-P2)/SE
Z
N1 = 511
P1 = 351/N1
N2 = 470
P2 = 296/N2
PHAT = P1-P2
SE= sqrt(P1*(1-P1)/N1+P2*(1-P2)/N2)
Z = (P1-P2)/SE
Z
alpha = 0.01
qnorm(1-alpha)
N1 = 511
P1 = 351/N1
N2 = 470
P2 = 296/N2
PHAT = P1-P2
SE= sqrt(P1*(1-P1)/N1+P2*(1-P2)/N2)
Z = (P1-P2)/SE
Z
alpha = 0.01
qnorm(1-alpha)
N1 = 511
P1 = 351/N1
N2 = 470
P2 = 296/N2
PHAT = P1-P2
SE= sqrt(P1*(1-P1)/N1+P2*(1-P2)/N2)
Z = (P1-P2)/SE
Z
alpha = 0.1
qnorm(1-alpha)
N1 = 511
P1 = 351/N1
N2 = 470
P2 = 296/N2
PHAT = P1-P2
SE= sqrt(P1*(1-P1)/N1+P2*(1-P2)/N2)
Z = (P1-P2)/SE
Z
